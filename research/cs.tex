\documentclass[a4paper,11pt,onecolumn]{article}
\usepackage[hscale=0.8,vscale=0.9]{geometry}
\usepackage[parfill]{parskip}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage{amssymb}

\newcommand{\eat}[1]{}

\begin{document}
\include{weld-defns}
\title{Research Statement}
\author{Niranjan Balasubramanian}
\maketitle

My research spans two broad areas: Information retrieval and Natural Language Processing. Applications like Question answering, event extraction and summarization systems, and web search providing easy access and organization to the vast amounts information on the web. These challenging applications require computer systems to extract, understand and reason with knowledge present in natural language texts. This long-standing Artificial Intelligence (AI) vision has tremendous societal and scientific impacts. My research is motivated by this vision and aims at building large scale open domain knowledge targeted towards specific applications.

%These are challenging applications that require computer systems to extract, organize, understand and reason with information in natural language texts. 
%I am motivated by applications that require computer systems to extract, organize, understand and reason with information in natural language texts. Pursuit of this long-standing Artificial Intelligence (AI) vision has tremendous societal and scientific impacts. For example applications like Question answering, event extraction, summarization systems, and web search provide easy access and organization to the vast amounts information on the web. Many of these challenging applications benefit from access to large scale open-domain knowledge.

%Applications like Question answering, event extraction and summarization systems augment web search by providing easy access and organization to the vast amounts information on the web. These are challenging applications that require computer systems to extract, organize, understand and reason with information in natural language texts. Pursuit of this long-standing Artificial Intelligence (AI) vision has tremendous societal and scientific impacts.
%I am motivated by applications that require computer systems to extract, organize, understand and reason with information in natural language texts. Pursuit of this long-standing Artificial Intelligence (AI) vision has tremendous societal and scientific impacts. Applications like Question answering, event extraction and summarization systems augment web search by providing easy access and organization to the vast amounts information on the web. These are challenging applications that require large scale open-domain knowledge. 

Consider a system answering a 4th grade science question:  ``Which is the best conductor of electricity? (A) metal fork (B) rubber boat''. The system needs access to the knowledge that i) a metal fork is made of metal, ii) metals conduct electricity, and iii) properties of a metal apply to things made of metal and reason with this knowledge to arrive at the answer. Consider an event extraction system that is "reading" an article about an arrest event. If the system had knowledge about what a typical arrest event is -- i.e., who the key actors are and what their roles are -- then it can use that information to identify the salient pieces to extract from the article. 

My current research focuses on developing methods for extracting such large scale open-domain knowledge and robust mechanisms for applying this knowledge. For wide applicability, I target methods that meet the following design goals: Scale to arbitrary domains, model semantics without ambiguity, and generalize to unseen contexts. I use Open Information Extraction (Open IE) techniques to extract open-domain relations and representations augmented with semantic classes to reduce ambiguity and improve generalization.

My research methods are centered on identifying the core aspects of the problem space through careful analysis of existing systems and data. For instance, in my work on event schemas, I analyzed output from previous system and identified the key shortcomings of underspecified representations. The insights led to a better representation that vastly improved the quality of the schemas. In my work on mobile search, I conducted a systematic study of data transfer costs in cellular networks. This study identified a key energy inefficiency, which spawned a large body of research aimed at minimizing its impact.~\footnote{This work has more than 350 citations.} 

Here I describe some of my research and lay out my vision for future work.

{\bf NLP [EMNLP 2013, AKBC-WEKEX 2012, 2013]}

{\bf Modeling Events}

Event schemas that specify actors and their roles within events are widely used in event extraction. Figure~\ref{fig:arrest} shows an example arrest schema. The key actors are an arresting agent who arrests and charges a suspect, a lawyer who represents the suspect and a judge who rules on the case. %Until recently, these were hand-engineered and consequently were limited to a small number of domains. 
My research aims to automatically generate these schemas from text with no manual effort with a specific focus on generating coherent schemas.

The main premise behind my work is that an accurate model of co-occurring actors and their actions can provide a basis for automatically generating schemas. The main challenge is in defining a suitable representation for the actions. My analysis of the output from a previous system showed that simpler (subject, verb) and (verb, object) pairs are underspecified representations that split critical context. In response, I developed an Open IE triple-based solution that uses a (Arg1, Relation, Arg2) triple that captures more specific information about the actions and reduces ambiguity. However, this reduction in ambiguity comes at a cost of increased sparsity and reduced generalization. 
\begin{wrapfigure}{r}{0.4\textwidth}
	\vspace{-2ex}
	\begin{center}
	\includegraphics[width=2.5in,height=2in]{figures/arrest-scenario} 	
	\vspace{-2ex}
	\caption{\label{fig:arrest} {\small Arrest schema: A model for an arrest scenario including key actors, the police, the suspect, judge etc. and their roles.}}
	\vspace{-2ex}
	\end{center}
\end{wrapfigure}
To counter this issue, I represent arguments using semantic classes, which allows the model to generalize beyond the specific entities to new unseen contexts. The relational co-occurrence model (Rel-grams) built over this triple representation yields a form of entailment type knowledge~\cite{balasubramanian-akbc12} and produces schemas that are more coherent than state-of-the-art systems~\cite{balasubramanian-emnlp13}.

{\bf Question Answering}

Achieving human-level performance on tasks that require intelligence has a long tradition in the history of AI. As one of the foundational members of the Allen Institute for Artificial Intelligence, I am co-leading efforts to design and develop a QA system that is capable of passing a 4th grade science exam.~\footnote{I also contribute to the long term research planning efforts and earlier co-wrote grant proposals with Dr. Oren Etzioni to obtain funding on earlier versions of this project.} This is an exciting long-term research project that seeks to address several fundamental challenges in representation, extraction and reasoning all in the context of a single task. 
\begin{wrapfigure}{l}{0.6\textwidth}
	\begin{center}
	\includegraphics[width=3in,height=2in]{figures/akbc} 	
	\vspace{-2ex}
	\caption{\label{fig:akbc} {\small Knowledge Requirements for passing a 4th Grade Science Exam}}
	\vspace{-2ex}
	\end{center}
\end{wrapfigure}

As a first step in this task, we studied the knowledge requirements for passing a 4th grade science exam~\cite{clark-akbc13}. The knowledge requirements summarized in Figure~\ref{fig:akbc} shows that this is a challenging task requiring a wide range of knowledge and robust reasoning methods. In addition to factual knowledge (e.g., iron conducts electricity), we identify three other types of useful knowledge: 1) Definitional knowledge, 2) Domain knowledge expressed via general purpose relations such as cause/effect, entity/function, 3) Implications representing domain and background knowledge (e.g., animal breathes oxygen $-$enables$\rightarrow$ animal make energy), and 4) Qualitative domain models (e.g., Reasoning with predator-prey models: If population of snakes rise, what happens to the population of frogs?).

We are building a wide array of solutions to address these difficult challenges. We extract definitional and general purpose relations such as cause/effect and entity/function using hand-generated lexico-syntactic patterns that exploit strong regularities in language. We use Open IE style relations to represent information but expand them to cover nested relations. In addition, we also use facts extracted using a state-of-the-art Open IE extractor. Our preliminary experiments show about 15\% improvement over simpler BOW baselines.

{\bf Information Retrieval [SIGIR 2010, CIKM 2009, IMC 2009, CoNext 2012]}


{\bf Combining Alternatives}

The IR research community continuously develops query representations, retrieval models, and various ranking algorithms. As part of my thesis, I developed a dynamic query-dependent approach for combining different alternatives. The main premise behind my thesis is that different alternatives work well for different queries. For example, a navigation query (intent to visit a specific url) is well served by user click based features, whereas a informational query is better served by query-document match features. If we can select the best choice(s) for a given query, then we can further improve retrieval performance. 

To this end, I developed a novel method that estimates the relative performance of the alternatives with respect to a baseline using easy to compute retrieval features~\cite{balasubramanian-sigir10a}. The key insight behind this method was that accurate estimation of the absolute effectiveness value was not essential. The estimation only needed to induce a good ordering of the available alternatives. This relative estimation method outperformed using the single best alternative for query representations~\cite{balasubramanian-sigir10b} and standard fusion methods for combining ranking functions~\cite{balasubramanian-sigir10c}. 


{\bf Topic Pages}

As an alternative to the typical web search paradigm, I built a system that automatically generates wikipedia like pages for queries~\cite{balasubramanian-icsc2010}. The primary challenge here is to identify the salient aspects pertaining to the query topic. I used web search logs to build diverse aspect models on topics. To generalize to topics beyond those that are observed in the search logs, I generalized the aspect models to include information from related topics. A second challenge here is to extract and organize information pertaining to the diverse aspects in a coherent fashion. I built a sentence extractor that identifies most typical connection between the topic and its aspect and used simple word-precedence models to organize the retrieved sentences. The resulting topic pages outperformed state-of-the-art summarization systems in terms of grammaticality, salience and coherence.

{\bf Mobile Search}

I studied the impact of system constraints on web search from mobile phones. I conducted a systematic study of how network activity consumed energy in mobile phones. My study revealed that energy consumption also depended on inter-transfer times in addition to the size of the data being transferred~\cite{balasubramanian-imc09}. Based on this insight, I designed interaction strategies that reduced the energy consumption of web search applications. In addition to improving the energy efficiency of web search, the key finding in this work led to a large body of work aimed at addressing the energy inefficiency.

I also worked on {\em FindAll}, a mobile search engine aimed at improving local availability of previously visited documents. Because indexing on the phone is expensive, the system must balance local availability against resource usage and energy consumption. Using actual search logs from mobile users, we learned user-specific re-finding patterns to predict when a user is likely to re-find documents. Using this predictive model, FindAll selectively indexes documents when cost of indexing is lower than cost of re-finding the document over the network. Evaluations show that FindAll dramatically improves local availability for heavy users without increasing the energy costs.

{\bf Future Work}

I am interested in extracting open-domain knowledge from text. In particular I want to extracting script-like descriptions of open-domain events and processes. My past work on Rel-grams and open event schemas provides a starting point but much work remains do be done. I am also interested in methods that can handle the gaps and noise inherent in such automatically extracted knowledge.
% In particular I wish to exploit existing semantic resources and extraction capabilities to build richer semantic structures at scale. I am also interested in developing robust application mechanisms to handle the gaps and noise inherent in such automatically extracted knowledge.

{\bf Script-like Knowledge}

Scripts are general purpose descriptions of events or scenarios. They include the key actors, their actions, and causal and temporal relationship between the different actions~\cite{schank-scripts75}. A dinner script for example is an ordered sequence of actions: An actor going to a restaurant, placing an order with a waiter, eating the food, and then paying the bill. 

If we read the sentences ``John went to Bill's restaurant and ordered steak. [He] paid \$50 for the meal.'', we easily infer that [He] refers to John and that John most likely ate the steak. Scripts provide valuable general purpose knowledge that can fill in these missing connections but aggregating high-quality scripts is a challenging task because many aspects of this knowledge are often implicit and harder to detect. I am interested in methods that can aggregate and generalize from explicitly mentioned aspects. 

For instance, causal links can be explicit (e.g., John ate lunch early {\em because} he was hungry) or implicit (e.g., John ate lunch early. He was hungry). The explicit mentions can be identified more reliably using lexical causal connectives (e.g, {\em because})  but the implicit links are harder. There are other structural constraints such as transitivity (i.e., A causes B and B causes C $\rightarrow$ A causes C) which can further improve precision. The bootstrapping task here is to detect explicit links with high-precision and then learn patterns over generalized representations of the actors and their actions. 

%A bootstrapping model can first detect the explicit links with high precision and then aggregate these causal links over generalized representations of the actors and the actions. For example, we can learn that if X ate then it was most likely because X was hungry.

%Scripts can help resolve ambiguous references in texts. Consider the following sentence: ``[People] travel to see their [families] when [they] find cheap flights to take [them]". [they] can resolve to families or [people]. Resolving pronouns in this sentence requires the system to know that the entity that travels is the one that is likely to find flights. Rel-grams provides a framework for aggregating this kind of background knowledge. One of the key challenges is the precision/recall trade-off. Past attempts at improving co-reference by adding semantics have mixed results because they either lack coverage or are too imprecise due to over-generalization. Rel-grams addresses this to some extent by including more context to improve accuracy and semantic classes to improve generalization. 

Scripts also serve as a template for extracting salient information about events by specifying the key actors and their actions. My past work on open event schemas produced coherent models of events in terms of the key actors and their roles and thus provide a strong basis constructing high-quality event extractors at scale. Expanding schemas to include extractors can also be viewed as a bootstrapping procedure starting from a strong high-quality model of an event. As with any bootstrapping approach the challenges are in finding appropriate sources for expansion and avoiding drifting from the source model. 


\eat{They are a powerful model of events including key actors, their roles and causal relationships~\cite{schank-scripts75}. Event schemas provide a start for building these script-like knowledge about events. However, they have limited generalization due to the use of a relatively smaller set of semantic classes. For example, the schemas cannot distinguish between a sports person and a baseball player. Moreover, the schemas do not include causality relations or temporal ordering of the actions within the schema. For example, the arrest schema does not  include information about whether the arrest precedes filing charges or vice versa. First, I wish to exploit high-quality entity linking systems and semantic resources such as NELL to expand to a much larger hierarchy of semantic classes. This raises interesting challenges: It is difficult to decide what semantic class to assign to a specific relation. In some cases a general category is preferable (e.g., ([sportsperson], failed, [drug test]) ), whereas in others a more specific category is preferable (e.g., ([baseball player], scored, home run)).  Second, I wish to leverage causality detection methods to annotate the schemas with causal relations. Even though these methods are not perfect, we can devise techniques that can prune errors in aggregation. }

\eat{Script like knowledge provide powerful models of events at discourse level by including key actors, their roles and causal relationships~\cite{schank-scripts75}. Rel-grams and schemas provide a start. However, their generalization is somewhat limited due to use of a limited set of semantic classes chosen in an ad-hoc fashion. Further, they do not include other valuable discourse relations such as causality and temporal ordering. First, I wish to exploit high-quality entity linking systems and semantic resources such as NELL to expand to a much larger hierarchy of semantic classes. This raises interesting challenges. For example, it is difficult to decide what semantic class to assign to a specific relation. In some cases a general category is preferable (e.g., ([sportsperson], failed, [drug test]) ), whereas in others a more specific category is preferable (e.g., ([baseball player], scored, home run)).  Second, I wish to leverage causality detection methods to annotate the schemas with causal relations. Even though these methods are not perfect, we can devise techniques that can prune errors in aggregation. }

\eat{
{\bf Event Extraction and Reference Resolution}

Scalable event extraction requires open domain models of events. Existing methods have used manual templates or use probabilistic methods that are unlikely to scale.%Past attempts have either used manual templates~\cite{patwardhan-emnlp09} or have used probabilistic methods that limit application to large scale open domain data~\cite{cheung-naacl13,chambers-emnlp13}. 
Open event schemas are coherent models of the key actors and their roles and thus provide a strong basis constructing high-quality extractors at scale. Expanding schemas to include extractors can be viewed as a bootstrapping procedure starting from a strong high-quality model of an event. As with any bootstrapping approach the challenges are in finding appropriate sources for expansion and avoiding drifting from the source model. 

Resolving co-reference is a challenging problem that requires broad semantic knowledge in the form of type constraints. Consider the following sentence: ``[People] travel to see their [families] when [they] find cheap flights to take [them]". [they] can resolve to families or [people]. Resolving pronouns in this sentence requires the system to know that the entity that travels is the one that is likely to find flights. Rel-grams provides a framework for aggregating this kind of background knowledge. One of the key challenges is the precision/recall trade-off. Past attempts at improving co-reference by adding semantics have mixed results because they either lack coverage or are too imprecise due to over-generalization. Rel-grams addresses this to some extent by including more context to improve accuracy and semantic classes to improve generalization.

{\bf Process Knowledge}
}
{\bf Reasoning with Automatically Extracted Knowledge}

Reasoning with knowledge extracted from texts require robust mechanisms to handle the inherent uncertainty, redundancy, and vocabulary mismatch issues. Previous textual entailment approaches that simply combine a large number of weak features. In contrast, I wish to explore approaches that preserve the deductive style of inference as much as possible, but fall back to weaker methods when necessary.  

To this end, I am interested in building a probabilistic reasoning framework. Specifically, I want to model question answering as a marginal inference problem in a Markov Logic Network (MLN) with text-based implications as first-order rules and Open IE style relations as evidence. Different from traditional applications of MLNs, the knowledge and rules here are textual, which result in gaps from vocabulary mismatch. To address these gaps, I will build a search solution that uses coarse but fast methods to locate plausible gaps and bridge them using deeper (more expensive) textual entailment techniques. The key challenges here include keeping the search space tractable and to have broad coverage entailment methods to handle lexical variations. 

%Reasoning with knowledge extractedd from texts requires robust approaches. However, past attempts at producing robust approaches has mainly resulted in everything in the kitchen sink style approaches. This has led to measured progress in textual entailment tasks, but they haven't shed much insights into the properties of the systems themselves or on the problem space. In contrast, I am interested in approaches that preserve the deductive style of inference as much as possible while falling back to distributional methods to bridge gaps but within the inference framework. This I believe combines the best of both worlds -- retains the robustness of the entailment style methods while also explicitly showing where the current knowledge is lacking or where textual reasoning is required. The question answering project is a great testbed to test these ideas.

{\bf Information Retrieval}

I am also interested in exploiting semantic knowledge for Information retrieval. In the past, IR applications have had mixed success with using semantic resources. The key limiting factor was the coverage of the resources used and scalability of the methods. Recent advances in large scale language processing and knowledge extraction techniques provide an ideal opportunity to test integration of semantics. Open Information Extraction presents an ideal starting point. It provides fast and a shallow representation of salient information in a corpus that can be used to improve retrieval. 


\eat{
%Resolving co-reference is a challenging problem that requires broad semantic knowledge~\cite{}. Consider the following sentence: ``[People] travel to see their [families] when [they] find cheap flights to take [them]". [they] can resolve to families or [people]. Resolving pronouns in this sentence requires the system to know that the entity that travels is the one that is likely to find flights. Rel-grams provides a framework for aggregating this kind of background knowledge. One of the key challenges is the precision/recall trade-off. Past attempts at improving co-reference by adding semantics have mixed results because they either lack coverage or are too imprecise due to over-generalization. Rel-grams addresses this to some extent by including more context to improve accuracy and semantic classes to improve generalization. [But more needs to be done... What?]

Question answering for passing grade science exams requires extraction and reasoning with implications knowledge. The work on Rel-grams provides a starting point but is seriously limited especially in terms of the amount of context captured. For example, consider the question about 
...\\
...\\
...\\


Reasoning with semantic resources constructed from texts requires robust approaches. However, past attempts at producing robust approaches has mainly resulted in everything in the kitchen sink style approaches. This has led to measured progress in textual entailment tasks, but they haven't shed much insights into the properties of the systems themselves or on the problem space. In contrast, I am interested in approaches that preserve the deductive style of inference as much as possible while falling back to distributional methods to bridge gaps but within the inference framework. This I believe combines the best of both worlds -- retains the robustness of the entailment style methods while also explicitly showing where the current knowledge is lacking or where textual reasoning is required. The question answering project is a great testbed to test these ideas...\\

Lastly, I am interested in exploiting semantic resources for Information retrieval. In the past, IR applications have had mixed success with using semantic resources. The key limiting factor was the coverage of the resources used...\\
}
{\small
\bibliographystyle{plain}
\bibliography{../research-statement,../kia}
}
\end{document}


\eat{As a first step in this challenging task, we studied the knowledge requirements for passing this exam~\cite{clark-akbc13}. The analysis presented several critical insights into the challenges that lay ahead. Figure~\ref{fig:knowledge-wheel} shows the required knowledge categories as a wheel. In addition to factual knowledge (e.g., iron conducts electricity), we identify three other types of useful knowledge: 1) Definitional knowledge: Terminology questions often test the ability of students to match terminology to its description. 2) Domain knowledge: A wide variety of domain knowledge expressed via general purpose relations such as cause/effect, action/purpose, entity/function and object/property. 3) Implications: To answer many questions the system requires knowledge represented as implications (e.g, animal breathes oxygen $-$enables$\rightarrow$ animal make energy). 4) Domain models: Modeling questions involve ability to reason with certain types of models (e.g. Reasoning with predator-prey models: If population of snakes rise, what happens to the population of frogs?). }

\documentclass[a4paper,11pt,onecolumn]{article}
\usepackage[hscale=0.8,vscale=0.9]{geometry}
\usepackage[parfill]{parskip}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amssymb}

\newcommand{\eat}[1]{}

\begin{document}
\include{weld-defns}
\title{Research Statement}
\author{Niranjan Balasubramanian}
\maketitle

My research is motivated by language applications that require open-domain semantic knowledge. Many fundamental problems in NLP require broad semantic knowledge: Event extraction and summarization benefit from models of events that include key actors and their roles. Reference resolution problems require broad semantic knowledge that specify type compatibility constraints. Question answering and textual entailment style applications often require large scale lexical paraphrase rules, as well as general inference rules that specify common sense and domain knowledge.
 
To be widely applicable, methods for constructing such semantic knowledge must meet the following design goals. First, they must scale to arbitrary domains and hence should not rely on domain specific models or resources. Second, the representation should be specific enough to model the semantics without ambiguity. Underspecified representations allow for robust estimation but often at the expense of increased ambiguity. When modeling events, a verb only representation will conflate relations that differ by the semantics of an attached proposition (e.g, in a lawsuit scenario the object of ``file by'' is a plaintiff and ``file against'' is a defendant).\eat{Further, using a verb only representation (without prepositions) might provide robust models for more verbs but cover fewer relations.} Finally, the methods must allow for generalization to new unseen contexts. For example, a semantic model about a smart-phone must generalize to be applicable for a related but newer context of Google glass.

%ii) scale to arbitrary domains with deep coverage, iii) generalize to new unseen contexts, and iv) be coherent. Prior attempts at generating such large scale resources are often too ambiguous and noisy because they lack critical context for application (e.g, DIRT and Verb Ocean).
\eat{
Prior work on event models (e.g. ACE and MUC templates) have largely relied on hand-generated templates which do not scale. Recent automatic methods broke through this limitation but suffer from quality issues. My prior work focused on building an event model with a representation that eliminates ambiguity, improves quality, while simultaneously improving generalization and coverage. Systems such as DIRT and Verb Ocean extract lexical paraphrase rules, and verb co-occurrence relations. Applications have met with little success because of the poor quality especially in the tail and the lack of enough context to ensure proper usage. Systems such as SHERLOCK and CLEAN learn more structured entailment rules in the form of Horn clauses over relations. While the quality is better than DIRT and Verb Ocean, they suffer from poor precision in the tail also. 
}
The goal of my work is to build methods that yield open domain, broad coverage techniques by careful design of representations that allow for appropriate generalization and specialization of knowledge and ensure coherence. My past work focused on building two types of semantic knowledge a) Rel-grams -- A form of entailment knowledge that captures what relation is likely to follow a given relation, and b) Open Schemas -- A model of the key actors and the roles they play in a scenario. 

\eat{
{\bf Query-dependent Models in IR}

The IR research community continuously develops query representations, retrieval models, and various ranking algorithms. 
These lead to a plethora of alternatives for system design and implementation. Until recently work on combining these alternatives was largely limited to simple fusion methods or static choices made at training time. As part of my thesis I developed a dynamic query-dependent approach for combining different alternatives. 

The main premise behind my thesis is that different alternatives work well for different queries. For example, a navigation query (intent to visit a specific url) is well served by user click based features, whereas a informational query is better served by query-document match features. If we can select the best choice(s) for a given query, then we can further improve retrieval performance. To this end, I first developed a model that estimated the performance of a particular result set based on simple aggregates of retrieval features~\cite{balasubramanian-sigir10a}. These simple features outperformed state-of-the-art content-based features. 

Next, I developed a new relative performance estimation method for selecting among the alternatives. The key insight behind this method was that accurate estimation of the absolute effectiveness value was not essential. The estimation only needed to induce a good ordering of the available alternatives. Therefore, I developed a model for estimating the relative effectiveness of the alternatives with respect to a baseline model. This relative estimation method results show substantial improvements over using a single best alternative for query representations~\cite{balasubramanian-sigir10b} and ranking functions~\cite{balasubramanian-sigir10c}. 

\newpage
}{\bf Modeling Events}

Representing and extracting events from text is one of the central problems in natural language processing~\cite{}. 
%Early work on {\em script theory} developed structured representations with actors and their roles to model events~\cite{schank-scripts75}. Similar structures are widely used for information extraction~\cite{patwardhan-emnlp09}. 
Past efforts mainly used hand-engineered representations and were naturally limited to a small number of domains(e.g., MUC templates and ACE event relations \cite{muc3,muc7,ace-lrec2004}). Recent automatic methods broke through this limitation scaled to arbitrary domains. However, they suffered from coherence issues due to inadequate representation and algorithmic limitations~\cite{chambers-acl09}. In response, I developed a Open Information Extraction (Open IE) based approach that extracts frequently co-occurring relations~\cite{balasubramanian-akbc12} and transforms them into schemas using a simple deterministic procedure~\cite{balasubramanian-emnlp13}. 

The main contribution of this work is in designing a suitable representation for modeling events. Simpler (subj, verb) or (verb, object) pairs used by Chambers and Jurafsky (2009) splits critical context leading to mixing distinct events. Instead I developed a more specific Open IE triple representation -- (Arg1, Rel, Arg2) -- that improves coherence. Using Open IE for relation extraction helps scale to arbitrary domains and provides a less ambiguous representation of an event. However, this reduction in ambiguity comes at a cost of increased sparsity and reduced generalization. To address this issue, I generalized the arguments using semantic classes identified through a small scale analysis on a development set. Using semantic classes also provided the opportunity to avoid merging distinct actors by enforcing type constraints. 
A large scale manual evaluation of the schemas generated from these Rel-grams showed that they substantially outperformed the existing state-of-the-art methods on a wide-range of coherence measures.
%The representation should capture adequate context, generalize beyond the observed representation, and be domain-independent.  

The second contribution of this work is a simple model of relational co-occurrence (Rel-grams) that captures a form of entailment~\cite{balasubramanian-akbc12}. Rel-grams can be viewed as a model of what follows a given relation under a given model of discourse. An evaluation of the top 10\% of rel-grams from a large news corpus showed that a surprisingly high percentage of rel-grams were valid implications in the real world. 

{\bf Question Answering}

Achieving human-level performance on tasks that require intelligence has a long tradition in the history of Artificial Intelligence~\cite{}. As one of the foundational members of the Allen Institute for Artificial Intelligence, I am co-leading efforts to design and develop a QA system that is capable of passing a 4th grade science exam. This is an exciting long-term research that seeks to address several fundamental challenges in AI representation, extraction and reasoning all in the context of a challenging question answering task.

As a first step in this challenging task, we studied the knowledge requirements for passing this exam~\cite{clark-akbc13}. The analysis presented several critical insights into the challenges that lay ahead. Figure~\ref{fig:knowledge-wheel} shows the required knowledge categories as a wheel. In addition to factual knowledge (e.g., iron conducts electricity), we identify three other types of useful knowledge: 1) Definitional knowledge: Terminology questions often test the ability of students to match terminology to its description. 2) Domain knowledge: A wide variety of domain knowledge expressed via general purpose relations such as cause/effect, action/purpose, entity/function and object/property. 3) Implications: To answer many questions the system requires knowledge represented as implications (e.g, animal breathes oxygen $-$enables$\rightarrow$ animal make energy). 4) Domain models: Modeling questions involve ability to reason with certain types of models (e.g. Reasoning with predator-prey models: If population of snakes rise, what happens to the population of frogs?). 

We are building a wide array of solutions to address these difficult challenges. We extract definitional and general purpose relations such as cause/effect and entity/function using hand-generated lexico-syntactic patterns that exploit strong regularities in language. We use Open IE style relations to represent information but expand them to cover nested relations. In addition, we also use facts extracted using a state-of-the-art Open IE extractor.

I am building a probabilistic reasoning framework that uses these knowledge sources to answer questions. Specifically, I cast question answering as a marginal inference problem in a Markov Logic Network (MLN) with implication knowledge as first-order rules and nested relations as evidence. Different from traditional applications of MLNs, the knowledge and rules here are textual, as a result of which several gaps arise due to vocabulary mismatch. To address these lexical gaps, I created an iterative bi-directional search algorithm that uses coarse but fast methods to locate plausible gaps and bridges them using deeper textual entailment techniques. One of the key challenges here is to restrict the backward-search to a feasible space. 

\eat{For acquiring definitional knowledge we exploit the strong regularities in definitional language to produce open ie style relations representing the definition. A typical definition includes the class or semantic type information about the term and one or more {\em definitional} properties. We used a handful of patterns covered 50\% of the definitions mined from the web at a high precision. For extracting domain knowledge, we use hand-generated dependency patterns to extract general purpose relations such as cause/effect. I am cure
}


{\bf Future Work}

I am interested in extracting open-domain semantic knowledge from text and its applications. In particular I wish to exploit existing semantic resources and extraction capabilities to build richer semantic structures at scale. I am also interested in developing robust mechanisms to handle the gaps and noise inherent in such automatically extracted knowledge.

Script like knowledge~\cite{schank-scripts75} can provide powerful models of events at a discourse level. They provide valuable background knowledge that is often necessary for understanding text. First, they capture the key actors involved in an event or scenario and the roles they play within it. This serves as a template for extracting salient information when "reading" documents. Second, knowing the typical roles played by actors can help resolve references in texts. Consider the following sentence: ``Police arrested the three suspects after [they]$^1$ found a large stash of cocaine in [their] apartment. [They]$^2$ were charged on Wednesday.''.  Knowledge about the typical roles played by police and suspects can guide the resolution of the pronouns in these sentences. Finally, knowledge about typical temporal/causal relations between the different events in an arrest scenario (search precedes arrest, which precedes filing charges) can help with temporal ordering and organization of information when presenting a summary of the text.

My past work on relational n-grams and open schemas generalized co-occurrence models beyond word-based and verb-based models to richer relation-level and scenario-level semantics. These open schemas meet the goals of being open domain and have sufficient representation power to reduce ambiguity. However, their generalization is somewhat limited due to use of a limited set of semantic classes chosen in an ad-hoc fashion and they do not include other valuable discourse relations such as causality and temporal ordering.

First, the availability of high-quality entity linking systems and semantic resources such as NELL~cite{} provide an opportunity to vastly expand the 
scope of semantic classes used to represent the arguments. However, using a hierarchy of semantic categories as in NELL also raises interesting challenges in deciding what granularity of semantic class to assign to a specific relation. In some cases a general category is preferable (e.g., ([sportsperson], failed, [drug test]) ), whereas a more specific category is preferable in others (e.g., ([baseball player], scored, home run)).

Second, recent advances in causality relation detection have resulted in technologies with high-precision and recall for finding explicitly stated causal relations in text. As with extraction errors that wash away in aggregation, I expect the errors in causality detection to wash away and present a strong signal  for building complete scripts. 


%%The open schemas model events as a set of actors and the roles they play within the event but lack fine-grained semantic classes and do not include causal/temporal relations. The semantic classes used cover a small number of semantic categories and were chosen in an ad-hoc fashion on a small dataset. 

Scalable event extraction requires open domain models of events in terms of the actors and their roles. Past attempts have either used manual templates~\cite{patwardhan-emnlp09} or have used probabilistic methods that limit application to large scale open domain data~\cite{cheung-naacl13,chambers-emnlp13}. Open event schemas are coherent models of the key actors and their roles and thus provide a strong basis constructing high-quality extractors at scale. Expanding schemas to include extractors can be viewed as a bootstrapping procedure starting from a strong high-quality model of an event. As with any bootstrapping approach the key challenges here are in finding appropriate sources for expansion and avoiding drifting far away from the source model. 
%Resolving co-reference is a challenging problem that requires broad semantic knowledge~\cite{}. Consider the following sentence: ``[People] travel to see their [families] when [they] find cheap flights to take [them]". [they] can resolve to families or [people]. Resolving pronouns in this sentence requires the system to know that the entity that travels is the one that is likely to find flights. Rel-grams provides a framework for aggregating this kind of background knowledge. One of the key challenges is the precision/recall trade-off. Past attempts at improving co-reference by adding semantics have mixed results because they either lack coverage or are too imprecise due to over-generalization. Rel-grams addresses this to some extent by including more context to improve accuracy and semantic classes to improve generalization. [But more needs to be done... What?]

Question answering for passing grade science exams requires extraction and reasoning with implications knowledge. The work on Rel-grams provides a starting point but is seriously limited especially in terms of the amount of context captured. For example, consider the question about 
...\\
...\\
...\\


Reasoning with semantic resources constructed from texts requires robust approaches. However, past attempts at producing robust approaches has mainly resulted in everything in the kitchen sink style approaches. This has led to measured progress in textual entailment tasks, but they haven't shed much insights into the properties of the systems themselves or on the problem space. In contrast, I am interested in approaches that preserve the deductive style of inference as much as possible while falling back to distributional methods to bridge gaps but within the inference framework. This I believe combines the best of both worlds -- retains the robustness of the entailment style methods while also explicitly showing where the current knowledge is lacking or where textual reasoning is required. The question answering project is a great testbed to test these ideas...\\

Lastly, I am interested in exploiting semantic resources for Information retrieval. In the past, IR applications have had mixed success with using semantic resources. The key limiting factor was the coverage of the resources used...\\

{\small
\bibliographystyle{plain}
\bibliography{research-statement,kia}
}
\end{document}
